[["index.html", "Advanced Microbiome Analysis 2025 Welcome", " Advanced Microbiome Analysis 2025 Welcome Welcome to CBW’s Advanced Microbiome Analysis 2025 Workshop! "],["course-schedule.html", "Course Schedule Meet Your Faculty", " Course Schedule Time (PST) Day 1 Time (PST) Day 2 8:30 Arrivals &amp; Check-in 8:30 Arrivals 9:00 Welcome (Coordinator) 9:00 Module 3 Lecture 9:30 Module 1 Lecture 10:30 Break (30min) 10:00 Break (30min) 11:00 Module 1 Lab 10:30 Module 3 Lab 13:00 Lunch (1h) 12:30 Class photo + Lunch (1h) 14:00 Module 2 Lecture 13:30 Module 4 Lecture 15:00 Break (30min) 14:30 Break (30min) 15:30 Module 2 Lab 15:00 Module 4 Lab 17:00 Survey and Closing Remarks 17:30 Finished 17:30 Finished Meet Your Faculty Coming soon! "],["module-1.html", "Module 1", " Module 1 "],["module-3-assigning-functions.html", "Module 3: Assigning Functions", " Module 3: Assigning Functions "],["module-3---lab-practical.html", "Module 3 - Lab practical Setting up the workspace Overview Prodigal Sequence similarity Machine learning Metabolic modelling", " Module 3 - Lab practical In this lab, we will predict and briefly examine the functions encoded in the assembled metagenome from the previous labs. All instructions required to completed this lab are provided below, so you are free to work asynchronously at your own pace. Active discussions with both peers and instructors are encouraged. Setting up the workspace Before we begin, this section will guide you through the set up of your workspace and compute environment. The software tools used in this lab all have dependencies that must be installed separately. Constructing the environment for each tool is non-trivial and error-prone. The difficulty of replicating compute environments for bioinformatics software is one of the key contributing factors to the reproducibility crisis [1]. We will instead be using prepackaged compute environments called “containers”, implemented by Apptainer (formerly Singularity) [2]. One of these containers will enable the use of jupyter notebooks along with a collection of utilities. Steps for setup: Open an additional port via SSH for the new jupyter notebook Create a new workspace directory for this lab Unpack and start the container Open the jupyter notebook in your browser References Mangul S, Martin LS, Eskin E, Blekhman R. Improving the usability and archival stability of bioinformatics software. Genome Biol. 2019;20(1):47. doi:10.1186/s13059-019-1649-8 Kurtzer GM, Sochat V, Bauer MW. Singularity: Scientific containers for mobility of compute. PLOS ONE. 2017;12(5):e0177459. doi:10.1371/journal.pone.0177459 SSH port forwarding Terminal (Unix/MacOS) Add -L 48888:localhost:48888 to the SSH command you use to connect to the server. For example: ssh -L 48888:localhost:48888 ubuntu@main.uhn-hpc.ca -i ${path_to_your_key} This means port 48888 on the remote server will be forwarded to your machine at localhost:48888. Putty (Windows) Modern versions of Windows should have ssh available through Powershell. Putty is available as a backup. Workspace Create a new workspace in your home directory. cd ~ mkdir amb_lab3 cd amb_lab3 Link the resource folder for easy access. ln -s ~/CourseData/MIC_data/amb_module3/ ./lib Start container Most containers for this lab were obtained from the biocontainers project, which provides a large collection of bioinformatics software in a standard format. For each tool, we will provide URIs for the the specific container image used and where to get future versions. The pull command of apptainer can be used to download images https://apptainer.org/docs/user/main/cli/apptainer_pull.html. Here is an example which downloads prodigal as the container image example.sif from docker://quay.io/biocontainers/prodigal:2.6.3--h7b50bb2_10. The image URI takes the form of &lt;protocol&gt;://&lt;address&gt;:&lt;tag&gt;. Tags are used to identify versions https://quay.io/repository/biocontainers/prodigal?tab=tags. apptainer pull example.sif docker://quay.io/biocontainers/prodigal:2.6.3--h7b50bb2_10 We can now run the prodigal executable inside the container using exec (execute) like so. apptainer exec ./example.sif prodigal -h All containers for this lab were pre-downloaded in the ./lib directory, including a main container with Jupyter and miscellaneous utilities. apptainer exec ./lib/amb_lab3.sif unpack The following will dedicate the current terminal to running the juptyer notebook on port 48888. You may want to connect another terminal to maintain terminal access. start_lab Jupyter JupyterLab should now be accessible at http://localhost:48888/lab. Create a new python notebook and import dependencies. import os, sys import pandas as pd from pathlib import Path from local.ipc import Shell LIB = Path(&quot;./lib&quot;) A special Shell function is provided to access the terminal outside the container. We can not run the container for another tool inside this container. Shell(f&quot;&quot;&quot; pwd -P echo {LIB} &quot;&quot;&quot;) Triple quotes allows multi-line strings. The f enables the evaluation of python variables in the string. For example, f\"echo {LIB}\" evaluates to echo ./lib. Overview This lab will guide you through finding and identifying the functional units (represented by the red and orange features below) of a metagenomic assembly, with a focus on proteins and enzymes. We will begin by exploring techniques related to sequence similarity, which seeks to identify known genes through comparison with reference databases. Prodigal Diamond Bakta Resistance Gene Identifier (RGI) Then we will transition to machine-learning tools, which move away from “lookup table” approach. Kofamscan deepFRI deepEC proteinBERT Finally, we will use gapseq to construct toy metabolic models using techniques to predict the existence of enzymes. gapseq Prodigal Containers are used to preserve the long-term executability of software tools used for this lab. https://quay.io/repository/biocontainers/prodigal?tab=tags # docker://quay.io/biocontainers/prodigal:2.6.3--h7b50bb2_10 prodigal_sif = LIB/&quot;prodigal.sif&quot; All containers for this lab To obtain a container with apptainer, we can use the pull command. # docker://quay.io/biocontainers/prodigal:2.6.3--h7b50bb2_10 prodigal_sif = LIB/&quot;prodigal.sif&quot; # docker://quay.io/biocontainers/prodigal:2.6.3--h7b50bb2_10 prodigal_sif = LIB/&quot;prodigal.sif&quot; Shell(f&quot;apptainer exec {prodigal_sif} prodigal -h&quot;) Shell(f&quot;&quot;&quot; mkdir -p prodigal_out apptainer exec {prodigal_sif} \\ prodigal \\ -i /data/inputs/mg1655.fna \\ -a ./prodigal_out/mg1655.faa \\ -d ./prodigal_out/mg1655.fna \\ -f gff \\ -o ./prodigal_out/mg1655.gff &quot;&quot;&quot;) Sequence similarity Diamond https://quay.io/repository/biocontainers/diamond?tab=tags # docker://quay.io/biocontainers/diamond:2.1.11--h5ca1c30_2 diamond_sif = LIB/&quot;diamond.sif&quot; Shell(f&quot;apptainer exec {diamond_sif} diamond --help&quot;) https://www.tcdb.org/public/tcdb https://www.tcdb.org/cgi-bin/substrates/getSubstrates.py https://www.tcdb.org/cgi-bin/substrates/listSuperfamilies.py https://www.tcdb.org/cgi-bin/projectv/public/families.py transporter_db = DATA/&quot;lib/transporter_classification_db&quot; transporter_dmdb = transporter_db/&quot;tcdb.dmnd&quot; if not transporter_dmdb.exists(): Shell(f&quot;&quot;&quot; apptainer exec {diamond_sif} diamond makedb \\ --threads {CPUS} \\ --in /data/lib/{transporter_db.name}/tcdb.faa \\ --db /data/lib/{transporter_db.name}/tcdb &quot;&quot;&quot;) TODO Shell(f&quot;&quot;&quot; apptainer exec {diamond_sif} \\ diamond blastp \\ --threads {CPUS} \\ &quot;&quot;&quot;) Bakta https://quay.io/repository/biocontainers/bakta?tab=tags # docker://quay.io/biocontainers/bakta:1.9.4--pyhdfd78af_0 bakta_sif = LIB/&quot;diamond.sif&quot; Shell(f&quot;apptainer exec {bakta_sif} bakta --help&quot;) Shell(f&quot;apptainer exec {bakta_sif} bakta_db list&quot;) # bakta_db = LIB/&quot;bakta_db/db&quot; # 2 hours bakta_db = LIB/&quot;bakta_db/db-light&quot; # 30 mins if not bakta_db.exists(): if &quot;light&quot; in str(bakta_db): _type = &quot;light&quot; else: _type = &quot;full&quot; Shell(f&quot;apptainer exec {bakta_sif} bakta_db download --output {bakta_db} --type {_type}&quot;) meta Shell(f&quot;&quot;&quot; apptainer exec {bakta_sif} \\ bakta --meta --threads {CPUS} --force --skip-plot \\ --db {bakta_db} \\ --output ./outputs/bakta.chicken \\ /home/tony/workspace/projects/AMB_2025/data/inputs/final.contigs.fa &quot;&quot;&quot;) Resistance Gene Identifier (RGI) https://quay.io/repository/biocontainers/rgi?tab=tags # docker://quay.io/biocontainers/rgi:6.0.4--pyh05cac1d_0 rgi_sif = LIB/&quot;rgi.sif&quot; Shell(f&quot;apptainer exec {rgi_sif} rgi --help&quot;) It looks like RGI accepts different commands (usage: rgi &lt;command&gt; [&lt;args&gt;]) and main seems to be the one that generates annotations. Shell(f&quot;apptainer exec {rgi_sif} rgi main --help&quot;) RGI is a bit picky and doesn’t provide any indication of progress or successful completion. Tackle the errors in the order in which they appear until you get a successful run, which should take no more than 1 min. Don’t worry about the SyntaxWarning since it looks like a typo in the source code that doesn’t otherwise impact the execution of the tool. Hint 1 Consider the inputs and outputs Hint 2 -i -o -t Hint Read-only file system -i -o -t Answer Shell(f&quot;&quot;&quot; mkdir -p ./outputs/rgi apptainer exec -B ./cache:/usr/local/lib/python3.12/site-packages/app/_db {rgi_sif} \\ rgi main --num_threads {CPUS} \\ -i ./outputs/bakta_light/mg1655.faa \\ -t protein \\ -o ./outputs/rgi/mg1655 &quot;&quot;&quot;) Stub: Shell(f&quot;&quot;&quot; # your solution here &quot;&quot;&quot;) Machine learning Kofamscan https://quay.io/repository/hallamlab/external_kofamscan?tab=tags # docker://quay.io/hallamlab/external_kofamscan:1.3.0 kofamscan_sif = LIB/&quot;kofamscan.sif&quot; Shell(f&quot;apptainer exec {kofamscan_sif} kofamscan --help&quot;) https://www.genome.jp/ftp/tools/kofam_scan/README.md Shell(f&quot;apptainer exec {kofamscan_sif} exec_annotation --help&quot;) ftp://ftp.genome.jp/pub/db/kofam/ko_list.gz ftp://ftp.genome.jp/pub/db/kofam/profiles.tar.gz # about 12 mins Shell(f&quot;&quot;&quot; mkdir -p ./outputs/kofamscan apptainer exec {kofamscan_sif} \\ exec_annotation \\ --cpu={CPUS} --format=detail --no-report-unannotated \\ --profile=/data/lib/kofamscan_db/profiles/prokaryote.hal --ko-list=/data/lib//kofamscan_db/ko_list \\ -o ./outputs/kofamscan/chicken.out \\ ./outputs/bakta.chicken/final.contigs.faa &quot;&quot;&quot;) from local.models.kegg_orthology import ParseKofamScanResults model = ParseKofamScanResults( Path(&quot;/home/tony/workspace/projects/AMB_2025/main/amb_lab3/scratch/mock/outputs/kofamscan/chicken.out&quot;), Path(&quot;/home/tony/workspace/projects/AMB_2025/data/lib/kofamscan_db/api_kegg.db&quot;), Path(&quot;/home/tony/workspace/projects/AMB_2025/data/lib/kofamscan_db/brite.json&quot;), ) deepFRI https://quay.io/repository/hallamlab/external_deepfri?tab=tags # docker://quay.io/hallamlab/external_deepfri:1.0.1 deepfri_sif = LIB/&quot;deepfri.sif&quot; Shell(f&quot;&quot;&quot; apptainer exec {deepfri_sif} \\ deepfri \\ --ont mf bp ec \\ --fasta_fn ./outputs/bakta.chicken/final.contigs.faa \\ --output_fn_prefix ./outputs/deepfri &quot;&quot;&quot;) deepEC https://quay.io/repository/hallamlab/external_deepec?tab=tags # docker://quay.io/hallamlab/external_deepec:0.4.1 deepec_sif = LIB/&quot;deepec.sif&quot; TODO proteinBERT https://quay.io/repository/hallamlab/external_proteinbert?tab=tags # docker://quay.io/hallamlab/external_proteinbert:2024.03.28 proteinbert_sif = LIB/&quot;proteinbert.sif&quot; TODO Metabolic modelling gapseq https://quay.io/repository/biocontainers/gapseq?tab=tags # docker://quay.io/biocontainers/gapseq:1.4.0--h9ee0642_1 gapseqt_sif = LIB/&quot;gapseq.sif&quot; Shell(f&quot;&quot;&quot; mkdir -p ./outputs/gapseq/ rm ./outputs/gapseq/mg1655.* apptainer exec {gapseq_sif} \\ gapseq find -p glycolysis -l KEGG -K 14 -O -f ./outputs/gapseq/mg1655 ./outputs/bakta_light/mg1655.faa \\ &gt; ./outputs/gapseq/mg1655.out 2&gt; ./outputs/gapseq/mg1655.err &quot;&quot;&quot;) Shell(f&quot;&quot;&quot; rm ./outputs/gapseq/mg1655.tr* apptainer exec {gapseq_sif} \\ gapseq find-transport -K 14 -f ./outputs/gapseq/mg1655 ./outputs/bakta_light/mg1655.faa \\ &gt; ./outputs/gapseq/mg1655.trout 2&gt; ./outputs/gapseq/mg1655.trerr &quot;&quot;&quot;) Shell(f&quot;&quot;&quot; apptainer exec {gapseq_sif} \\ gapseq draft \\ -r ./outputs/gapseq/mg1655/mg1655-glycolysis-Reactions.tbl \\ -p ./outputs/gapseq/mg1655/mg1655-glycolysis-Pathways.tbl \\ -t ./outputs/gapseq/mg1655/mg1655-Transporter.tbl \\ -c ./outputs/bakta_light/mg1655.faa \\ -f ./outputs/gapseq/mg1655 &quot;&quot;&quot;) Shell(f&quot;&quot;&quot; apptainer exec {gapseq_sif} \\ gapseq fill --quick.gf \\ -m ./outputs/gapseq/mg1655/mg1655-draft.RDS \\ -n ./outputs/gapseq/mg1655/m9.csv \\ --output.dir ./outputs/gapseq/mg1655 &quot;&quot;&quot;) TODO: kegg mapper look at what reactions were filled "],["module-4-visualization-and-finding-functional-significance.html", "Module 4: Visualization and Finding Functional Significance", " Module 4: Visualization and Finding Functional Significance "],["module-4---lab-practical.html", "Module 4 - Lab practical Overview Setting up the workspace Salmon Deseq2 Gene set enrichment analysis (GSEA)", " Module 4 - Lab practical Overview Salmon Deseq2 Gene set enrichment analysis (GSEA) [Cytoscape] Setting up the workspace The following procedure to set up the workspace will be near identical to that of the previous lab. The compute environment All software dependencies for this lab are packaged as containers. Port forward Terminal (Unix/MacOS) ssh -L 48888:localhost:48888 ubuntu@main.uhn-hpc.ca -i ${path_to_your_key} Putty (Windows) how to set port forward with putty Start container apptainer exec ./amb_2025.sif unpack start_lab Jupyter http://localhost:48888/lab import os, sys import pandas as pd from pathlib import Path from local.ipc import Shell from local.constants import WORKSPACE_ROOT LIB = WORKSPACE_ROOT/&quot;lib&quot; if not LIB.exists(): LIB.mkdir() DATA = Path(&quot;/home/tony/workspace/projects/AMB_2025/data&quot;) Shell(&quot;pwd -P&quot;) Salmon os.system(f&quot;salmon --help&quot;) os.system(f&quot;salmon index --help&quot;) os.system(f&quot;salmon quant --help&quot;) assembly = Path(&quot;/home/tony/workspace/projects/AMB_2025/main/amb_lab3/scratch/mock/outputs/bakta.chicken/final.contigs.ffn&quot;) index = WORKSPACE_ROOT/&quot;asm_index&quot; os.system(f&quot;salmon index -t {assembly} -i {index}&quot;) # 6 mins reads_dir = Path(&quot;/home/tony/workspace/projects/AMB_2025/data/inputs/reads_for_assembly&quot;) todo = list(reads_dir.iterdir()) for read_file in tqdm(todo, total=len(todo)): srr = read_file.name.split(&quot;_&quot;)[0] out = WORKSPACE_ROOT/f&quot;salmon/{srr}&quot; os.system(f&quot;&quot;&quot; mkdir -p {out} salmon quant -i {index} -l A -p 14 \\ -r {read_file} \\ -o {out} &gt;{out}/salmon.log 2&gt;{out}/salmon.err &quot;&quot;&quot;) Deseq2 look at 1 quant.sf file out_dir = Path(&quot;/home/tony/workspace/projects/AMB_2025/main/amb_lab4/scratch/mock/salmon&quot;) # look at the quant.sf file for srr in out_dir.iterdir(): df = pd.read_csv(srr/&quot;quant.sf&quot;, sep=&quot;\\t&quot;) break df df_meta = pd.read_csv(&quot;/home/tony/workspace/projects/AMB_2025/data/inputs/metagenome_metadata.txt&quot;, sep=&quot;\\t&quot;) print(df_meta.shape) df_meta.head(2) out_dir = Path(&quot;/home/tony/workspace/projects/AMB_2025/main/amb_lab4/scratch/mock/salmon&quot;) mtx = np.zeros(shape=(len(gene2i), len(todo)), dtype=np.int32) # genes x samples for i, srr in tqdm(enumerate(df_meta[&quot;sample_name&quot;]), total=len(df_meta)): df = pd.read_csv(out_dir/f&quot;{srr}/quant.sf&quot;, sep=&quot;\\t&quot;) gene_indexes = [gene2i[row[&quot;Name&quot;]] for _, row in df.iterrows()] counts = df[&quot;NumReads&quot;] mtx[gene_indexes, i] = counts mtx.shape gene_ids = list(gene2i.keys()) sample_ids = list(df_meta[&quot;sample_name&quot;]) df = pd.DataFrame(mtx[:, :, 0], columns=sample_ids) df[&quot;gene_id&quot;] = gene_ids df = df.set_index(&quot;gene_id&quot;) print(df.shape) df.to_csv(WORKSPACE_ROOT/&quot;salmon/counts.mtx&quot;) df.head(2) Transistion to an R notebook. http://localhost:48888/lab library(DESeq2) library(readr) cts &lt;- as.matrix(read.csv( &quot;/home/tony/workspace/projects/AMB_2025/main/amb_lab4/scratch/mock/salmon/counts.mtx&quot;, row.names = &quot;gene_id&quot; )) coldata &lt;- read.csv( &quot;/home/tony/workspace/projects/AMB_2025/data/inputs/metagenome_metadata.txt&quot;, sep = &quot;\\t&quot;, ) We will compare Bacteroides vs Non-Bacteroides coldata$grouping dds &lt;- DESeqDataSetFromMatrix( countData = cts, colData = coldata, design = ~ grouping ) dds dds &lt;- DESeq(dds) deseq_save &lt;- &quot;/home/tony/workspace/projects/AMB_2025/main/amb_lab4/scratch/mock/deseq2.rds&quot; if (!file.exists(deseq_save)) { dds &lt;- DESeq(dds) saveRDS(dds, deseq_save) } else { dds &lt;- readRDS(deseq_save) } res &lt;- results(dds, contrast = c(&quot;grouping&quot;, &quot;Bacteroides&quot;, &quot;Non-Bacteroides&quot;)) results_table &lt;- as.data.frame(res) write.csv(results_table, &quot;/home/tony/workspace/projects/AMB_2025/main/amb_lab4/scratch/mock/deseq2_results.csv&quot;, row.names = TRUE) Next, we will compute a null distribution for Gene set enrichment analysis (GSEA). GSEA randomly assigns conditions to samples to compute the null distribution. When the number of samples is low, genes can be randomly assigned to gene sets instead, but this fails to take into account gene-gene correlations. What is the minimum number of samples to simulate a null distribution with a precision of at least 0.05? 4! = 24. 1/24 is about 0.04. This will be explored further in the next section. normalized counts vst &lt;- vst(dds, blind = FALSE) vst_counts &lt;- assay(vst) coldata$grouping class_labels_numeric &lt;- 1 - (as.numeric(factor(coldata$grouping)) - 1) class_labels_numeric The point biserial correlation is a special case of the Pearson correlation designed to compare a continuous variable with a binary variable. Alternatively the biserial correlation compares the same, but assumes that the binary variable is the result of thresholding a continuous variable. For example, it would be appropriate to use the point biserial correlation for a coin toss, while the biserial correlation would be more appropriate for pass/fails from percentage grades. Practically, the biserial correlation also requires the relative propotions of each class. We will compute the point biserial correlation between genes and conditions for GSEA. While there likely is a genetic spectrum of bacteria spanning from Bacteroides to Non-Bacteroides, the chicken gut microbiome likely doesn’t have sufficient diversity to realize this spectrum. point_biserial &lt;- function(expression, classes) { if (sd(expression) == 0) return(NA) return(cor(expression, classes, method = &quot;pearson&quot;)) } gene_correlations &lt;- apply(vst_counts, 1, point_biserial, classes = class_labels_numeric) gene_correlations &lt;- as.data.frame(gene_correlations) write.csv(gene_correlations, &quot;/home/tony/workspace/projects/AMB_2025/main/amb_lab4/scratch/mock/gene_correlations.csv&quot;, row.names = TRUE) library(pbapply) bootstrap_save &lt;- &quot;/home/tony/workspace/projects/AMB_2025/main/amb_lab4/scratch/mock/null_distr.csv&quot; # about 1 minute if (!file.exists(bootstrap_save)) { tryCatch( { cl &lt;- makeCluster(8) # N cpus clusterExport(cl, c(&quot;vst_counts&quot;, &quot;point_biserial&quot;, &quot;class_labels_numeric&quot;)) n_permutations &lt;- 200 permutation_results &lt;- pbsapply( 1:n_permutations, function(i) { # Shuffle labels n &lt;- length(class_labels_numeric) shuffled_labels &lt;- sample(class_labels_numeric, size = n, replace = FALSE) # Calculate correlations for all genes return(apply(vst_counts, 1, point_biserial, classes = shuffled_labels)) }, cl = cl # This enables parallel processing ) }, finally = { stopCluster(cl) } ) null_distr &lt;- data.frame( sample = permutation_results, stringsAsFactors = FALSE ) write.csv( null_distr, bootstrap_save, row.names = TRUE ) } else { null_distr &lt;- read.csv(bootstrap_save) } dim(null_distr) Gene set enrichment analysis (GSEA) from local.models.kegg_orthology import ParseKofamScanResults model = ParseKofamScanResults( Path(&quot;/home/tony/workspace/projects/AMB_2025/main/amb_lab3/scratch/mock/outputs/kofamscan/chicken.out&quot;), Path(&quot;/home/tony/workspace/projects/AMB_2025/data/lib/kofamscan_db/api_kegg.db&quot;), Path(&quot;/home/tony/workspace/projects/AMB_2025/data/lib/kofamscan_db/brite.json&quot;), ) function2genes = {} for _, r in model.df.iterrows(): ko = r[&quot;ko&quot;] orf = r[&quot;orf&quot;] function2genes[ko] = function2genes.get(ko, set())|{orf} reactions2functions = {} for ko in function2genes: meta = model.Functions[ko] for r in meta.reactions: reactions2functions[r] = reactions2functions.get(r, set())|{ko} pathway2reactions = {} for r in reactions2functions: meta = model.Reactions[r] for p in meta.pathways: pathway2reactions[p] = pathway2reactions.get(p, set())|{r} gene_sets = {} for p, reactions in pathway2reactions.items(): genes = set() for r in reactions: functions = reactions2functions[r] for f in functions: genes |= function2genes[f] gene_sets[p] = genes from dataclasses import dataclass @dataclass class GseaResult: set_name: str set_size: int score: float pvalue: float hits: np.ndarray running_sum_statistic: np.ndarray class Gsea: def __init__(self, labels: np.ndarray, corr: np.ndarray, permuted: np.ndarray) -&gt; None: self.labels = labels mat = np.hstack([corr, permuted]) self.mat_index = np.argsort(-mat.T, stable=True) self.mat_sorted = np.zeros_like(mat) for i, order in enumerate(self.mat_index): self.mat_sorted[:, i] = mat[:, i][order] def run(self, name: str, gene_set: set, p=1): S = np.array([k in s for k in self.labels], dtype=int) S = S[self.mat_index.T] corr = np.pow(np.abs(self.mat_sorted), p) N_R = np.sum(corr*S, axis=0) P_hit = corr/N_R P_hit = P_hit*S # g_j in S P_hit = np.cumsum(P_hit, axis=0) miss = 1/(len(self.labels) - len(s)) miss = np.ones_like(self.labels)*(1-S.T)*miss P_miss = np.cumsum(miss.T, axis=0) S_distr = (P_hit - P_miss).T ES_pos = S_distr.max(axis=1) ES_neg = S_distr.min(axis=1) ES_candidates = np.vstack([ES_pos, ES_neg]).T to_take = np.argmax(np.abs(ES_candidates), axis=1) ES = (ES_neg*to_take) + (ES_pos*(1-to_take)) score, boot = ES[0], ES[1:] pvalue = np.sum(boot &gt;= score) / boot.shape[0] if pvalue == 0: pvalue = 1 / boot.shape[0] return GseaResult( set_name=name, set_size=len(gene_set), score=score, pvalue=pvalue, hits=S.T[0], running_sum_statistic=S_distr[0], ) def _only_enzymes(df: pd.DataFrame): return df.loc[df.index.isin(enzymes)] _df_corr_e = _only_enzymes(df_corr) gsea = Gsea( labels=_df_corr_e.index.to_numpy(), corr=_df_corr_e.to_numpy(), permuted=_only_enzymes(df_bootstrap).to_numpy(), ) results: list[GseaResult] = [] for k, s in tqdm(gene_sets.items(), total=len(gene_sets)): res = gsea.run(k, s) results.append(res) results_map = {r.set_name: r for r in results} def draw_gsea(res: GseaResult, gsea: Gsea): k = res.set_name fig = BaseFigure( shape=(1, 3), row_heights=[0.2, 0.2, 0.6], vertical_spacing=0.05, ) _f = res.hits.astype(bool) fig.add_trace( go.Scatter( x = np.arange(gsea.labels.shape[0])[_f], y = np.zeros_like(gsea.labels)[_f], mode = &quot;markers&quot;, marker=dict( size=25, color=COLORS.TRANSPARENT, symbol=&quot;line-ns&quot;, line=dict(width=1), ), showlegend=False, ), col=1, row=1, ) fig.add_trace( go.Bar( x = np.arange(gsea.labels.shape[0]), y = gsea.mat_sorted.T[0], showlegend=False, marker=dict( color=COLORS.BLACK, line=dict(width=0), ), ), col=1, row=2, ) fig.add_trace( go.Scatter( x = np.arange(gsea.labels.shape[0]), y = res.running_sum_statistic, mode = &quot;lines&quot;, showlegend=False, line=dict( color = COLORS.BLACK, ), ), col=1, row=3, ) hidden = dict(ticks=None, linecolor=COLORS.TRANSPARENT, showticklabels=False) fig = ApplyTemplate( fig, default_xaxis=hidden, default_yaxis=hidden, layout=dict( width=600, height=400, margin=dict(l=15, r=15, t=50, b=15), title=dict(text=f&quot;(p={res.pvalue}) {k}:{model.Pathways[k].name}&quot;, font_size=18, x=0.5), ), ) fig.show() draw_gsea(results_map[&quot;rn00600&quot;], gsea) results = sorted(results, key=lambda x: x.pvalue) for r in results[15:35]: meta = model.Pathways[r.set_name] print(f&quot;{r.pvalue:.2} {r.score:.2} {r.set_name}:{meta.name}&quot;) draw_gsea(results_map[&quot;rn00260&quot;], gsea) "],["404.html", "Error 404: This page does not exist.", " Error 404: This page does not exist. This page does not exist anymore! Try going back to the workshop homepage or the bioinformatics.ca homepage. You must update these pages for new workshops. "]]
